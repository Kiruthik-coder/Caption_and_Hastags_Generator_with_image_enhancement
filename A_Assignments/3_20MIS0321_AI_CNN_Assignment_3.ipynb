{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594df09d-909f-40f7-85be-e794f9710476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20MIS0321 - AI Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d1e176-c3d4-4387-ad6d-f8ae8eaf8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dabe4513-4f35-4a02-8a69-064b70830cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 images belonging to 16 classes.\n",
      "Found 158 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "# Here we are performing Data augumentation\n",
    "train_gen = ImageDataGenerator(rescale=(1./255),horizontal_flip=True,shear_range=0.2)\n",
    "test_gen = ImageDataGenerator(rescale=(1./255))  #--> (0 to 255) convert to (0 to 1)\n",
    "     \n",
    "\n",
    "# Assigning data to variables.\n",
    "train = train_gen.flow_from_directory('archive/train_data/train_data',\n",
    "                                      target_size=(120, 120),\n",
    "                                      class_mode='categorical', \n",
    "                                      batch_size=16)\n",
    "test = test_gen.flow_from_directory('archive/test_data/test_data',\n",
    "                                    target_size=(120, 120),\n",
    "                                      class_mode='categorical', \n",
    "                                      batch_size=16)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3548c8aa-d19d-46d1-9289-a4fbba2da98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blasti': 0,\n",
       " 'bonegl': 1,\n",
       " 'brhkyt': 2,\n",
       " 'cbrtsh': 3,\n",
       " 'cmnmyn': 4,\n",
       " 'gretit': 5,\n",
       " 'hilpig': 6,\n",
       " 'himbul': 7,\n",
       " 'himgri': 8,\n",
       " 'hsparo': 9,\n",
       " 'indvul': 10,\n",
       " 'jglowl': 11,\n",
       " 'lbicrw': 12,\n",
       " 'mgprob': 13,\n",
       " 'rebimg': 14,\n",
       " 'wcrsrt': 15}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43aec09f-9c24-4819-92e5-ae650a3842b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - M o d e l - - - \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Input Conv Layer\n",
    "model.add(Convolution2D(12,(3,3),activation='relu',input_shape=(120, 120, 3)))\n",
    "\n",
    "# Normalizing using Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "model.add(Convolution2D(24,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "model.add(Convolution2D(36,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "model.add(Flatten()) #Flatterning into vector\n",
    "\n",
    "\n",
    "# Hiddern layers -----------------------------------------------------------------\n",
    "model.add(Dense(62,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "\n",
    "\n",
    "# Output final layer -------------------------------------------------------------\n",
    "model.add(Dense(16,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7403057d-628a-4aa5-8bf0-4a061ca799f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 37s 4s/step - loss: 2.9552 - accuracy: 0.0658 - val_loss: 2.7916 - val_accuracy: 0.0382\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 2.5762 - accuracy: 0.1711 - val_loss: 2.7611 - val_accuracy: 0.0382\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 2.4164 - accuracy: 0.2566 - val_loss: 2.7602 - val_accuracy: 0.1338\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 2.3102 - accuracy: 0.2961 - val_loss: 2.7628 - val_accuracy: 0.1465\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 2.1652 - accuracy: 0.3684 - val_loss: 2.7810 - val_accuracy: 0.1720\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 2.0517 - accuracy: 0.4211 - val_loss: 2.8450 - val_accuracy: 0.0955\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 2.0083 - accuracy: 0.4342 - val_loss: 2.8991 - val_accuracy: 0.0955\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.8588 - accuracy: 0.4737 - val_loss: 2.9044 - val_accuracy: 0.0955\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.7429 - accuracy: 0.5329 - val_loss: 3.0468 - val_accuracy: 0.0955\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.6484 - accuracy: 0.5592 - val_loss: 3.2251 - val_accuracy: 0.0955\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.6494 - accuracy: 0.4934 - val_loss: 3.4913 - val_accuracy: 0.0955\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.5972 - accuracy: 0.5724 - val_loss: 3.5086 - val_accuracy: 0.0955\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.4398 - accuracy: 0.5987 - val_loss: 3.5143 - val_accuracy: 0.0955\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.3265 - accuracy: 0.6250 - val_loss: 3.9242 - val_accuracy: 0.0955\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.2787 - accuracy: 0.6513 - val_loss: 4.0846 - val_accuracy: 0.0955\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 1.1653 - accuracy: 0.6579 - val_loss: 3.7786 - val_accuracy: 0.1083\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.1248 - accuracy: 0.6776 - val_loss: 3.9952 - val_accuracy: 0.0955\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 1.0919 - accuracy: 0.7105 - val_loss: 4.1221 - val_accuracy: 0.0955\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 0.9783 - accuracy: 0.7368 - val_loss: 4.1791 - val_accuracy: 0.0955\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.9563 - accuracy: 0.7434 - val_loss: 4.4804 - val_accuracy: 0.0955\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 0.8427 - accuracy: 0.7829 - val_loss: 4.6856 - val_accuracy: 0.0955\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 0.7587 - accuracy: 0.8158 - val_loss: 4.9961 - val_accuracy: 0.0955\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.7277 - accuracy: 0.8092 - val_loss: 5.2496 - val_accuracy: 0.0955\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.6361 - accuracy: 0.8355 - val_loss: 5.0207 - val_accuracy: 0.0955\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 0.5747 - accuracy: 0.8553 - val_loss: 5.5483 - val_accuracy: 0.1019\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.4578 - accuracy: 0.8947 - val_loss: 5.0052 - val_accuracy: 0.0955\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 34s 4s/step - loss: 0.4753 - accuracy: 0.8882 - val_loss: 5.1902 - val_accuracy: 0.0955\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.5712 - accuracy: 0.8684 - val_loss: 5.2826 - val_accuracy: 0.0955\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.5500 - accuracy: 0.8684 - val_loss: 4.7091 - val_accuracy: 0.1019\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.4655 - accuracy: 0.8750 - val_loss: 5.1525 - val_accuracy: 0.1083\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.4826 - accuracy: 0.8882 - val_loss: 4.1372 - val_accuracy: 0.1401\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.4097 - accuracy: 0.8947 - val_loss: 4.5677 - val_accuracy: 0.1083\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.3723 - accuracy: 0.9211 - val_loss: 4.8609 - val_accuracy: 0.1083\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.2606 - accuracy: 0.9539 - val_loss: 4.6266 - val_accuracy: 0.1019\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.2881 - accuracy: 0.9342 - val_loss: 5.0913 - val_accuracy: 0.1083\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.3380 - accuracy: 0.8947 - val_loss: 4.9616 - val_accuracy: 0.1210\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.2888 - accuracy: 0.9474 - val_loss: 4.6595 - val_accuracy: 0.1019\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.3377 - accuracy: 0.9145 - val_loss: 5.0555 - val_accuracy: 0.1083\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.3006 - accuracy: 0.9408 - val_loss: 5.1149 - val_accuracy: 0.1019\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.2797 - accuracy: 0.9211 - val_loss: 5.1431 - val_accuracy: 0.1210\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.3068 - accuracy: 0.9276 - val_loss: 4.6331 - val_accuracy: 0.1592\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.2343 - accuracy: 0.9474 - val_loss: 4.9764 - val_accuracy: 0.1146\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.2235 - accuracy: 0.9408 - val_loss: 4.8832 - val_accuracy: 0.0955\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.2182 - accuracy: 0.9671 - val_loss: 4.4089 - val_accuracy: 0.1401\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.1853 - accuracy: 0.9605 - val_loss: 4.4578 - val_accuracy: 0.1847\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.1707 - accuracy: 0.9671 - val_loss: 4.8305 - val_accuracy: 0.1783\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.1541 - accuracy: 0.9803 - val_loss: 4.8331 - val_accuracy: 0.1720\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.1227 - accuracy: 0.9868 - val_loss: 4.7171 - val_accuracy: 0.1783\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.1538 - accuracy: 0.9737 - val_loss: 4.6004 - val_accuracy: 0.2038\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.1805 - accuracy: 0.9474 - val_loss: 4.7807 - val_accuracy: 0.1911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b7e2260>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train,batch_size=16,validation_data=test,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c882fc1-a175-41c2-b2df-06a6670dcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Birds_Model_2.h5')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1adfd99a-842a-4335-bbec-4b4f45099377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can not the model is overfitting for the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb92182-a71a-4df5-a67f-71165edfe43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we try using transfer learning technique and lets see the difference\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Using VGG16 pre trained model and using imagenet weights\n",
    "trained_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(120, 120, 3))\n",
    "trained_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c090721-44b0-4e7e-96b2-dd86843d9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are adding last few layers accourding to our dataset\n",
    "\n",
    "flatten = layers.Flatten()\n",
    "dense1 = layers.Dense(50, activation='relu')\n",
    "dense2 = layers.Dense(20, activation='relu')\n",
    "pred = layers.Dense(16, activation='softmax') #16 classes are there\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    trained_model,\n",
    "    flatten,\n",
    "    dense1,\n",
    "    dense2,\n",
    "    pred\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "864538e0-4302-4c18-acfa-68544bb0eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0730 - accuracy: 0.9934 - val_loss: 4.3102 - val_accuracy: 0.3608\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0498 - accuracy: 0.9868 - val_loss: 4.5394 - val_accuracy: 0.3797\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0424 - accuracy: 0.9934 - val_loss: 4.4172 - val_accuracy: 0.3608\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 4.3620 - val_accuracy: 0.4051\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 4.5013 - val_accuracy: 0.3671\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 4.5983 - val_accuracy: 0.3608\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 4.6374 - val_accuracy: 0.3671\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 4.6696 - val_accuracy: 0.3671\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 4.7340 - val_accuracy: 0.3671\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 4.7552 - val_accuracy: 0.3544\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.7741 - val_accuracy: 0.3608\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.9050 - val_accuracy: 0.3671\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.7753 - val_accuracy: 0.3671\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.8861 - val_accuracy: 0.3671\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.9779 - val_accuracy: 0.3608\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 5.0171 - val_accuracy: 0.3671\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.0457 - val_accuracy: 0.3608\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.0679 - val_accuracy: 0.3608\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.0813 - val_accuracy: 0.3608\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.1334 - val_accuracy: 0.3481\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.1687 - val_accuracy: 0.3608\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.1700 - val_accuracy: 0.3544\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.2042 - val_accuracy: 0.3608\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.2021 - val_accuracy: 0.3544\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.2610 - val_accuracy: 0.3544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15637dff0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(train,batch_size=16,validation_data=test,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2afa50b-94db-4fd8-ae26-4e5efbf71033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the overfitting is reduced a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af10a1b8-081c-4f76-bca0-1c3e770b32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Birds_Model_by_transfer_learning.h5') # saving trasfered learned model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e5035-d78f-490b-8713-07f3e358f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Model - with test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77b30841-1473-49e5-82f2-02fab16c3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "2\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img1 = image.load_img('archive/test_data/test_data/brhkyt/D72_0479.jpg',target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "output = [\"blasti\", \"bonegl\", \"brhkyt\", \"cbrtsh\", \"cmnmyn\", \"gretit\", \"hilpig\", \"himbul\", \"himgri\", \"hsparo\", \"indvul\", \"jglowl\"\n",
    " ,\"lbicrw\", \"mgprob\", \"rebimg\", \"wcrsrt\"]\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac68822d-c481-4282-8386-97c4ae50b450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "4\n",
      "cmnmyn\n"
     ]
    }
   ],
   "source": [
    "img1 = image.load_img('archive/test_data/test_data/cmnmyn/_D32_12428.jpg',target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "output = [\"blasti\", \"bonegl\", \"brhkyt\", \"cbrtsh\", \"cmnmyn\", \"gretit\", \"hilpig\", \"himbul\", \"himgri\", \"hsparo\", \"indvul\", \"jglowl\"\n",
    " ,\"lbicrw\", \"mgprob\", \"rebimg\", \"wcrsrt\"]\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "719f2156-3a21-4f5d-bc5a-d624c97f3188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "15\n",
      "wcrsrt\n"
     ]
    }
   ],
   "source": [
    "img1 = image.load_img('archive/test_data/test_data/wcrsrt/100_4466.JPG',target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "output = [\"blasti\", \"bonegl\", \"brhkyt\", \"cbrtsh\", \"cmnmyn\", \"gretit\", \"hilpig\", \"himbul\", \"himgri\", \"hsparo\", \"indvul\", \"jglowl\"\n",
    " ,\"lbicrw\", \"mgprob\", \"rebimg\", \"wcrsrt\"]\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f97109-b7fe-40d2-b4ae-f7b849c1353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20MIS0321 - E n d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
